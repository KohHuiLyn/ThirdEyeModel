{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Final Year Project - The Third Eye </h1>\n",
    "Done by: See Zhuo Yi Joey (2011927), Liu Zhen (2021250), Koh Hui Lyn (2021672) and Ang Jun Hoa (2040295)\n",
    "<br/>Project Aim: Using computer vision to aid coach’s analysis of a bowler’s performance by producing consistent and accurate intelligent analysis.\n",
    "<br/>Modules Required: MediaPipe, OpenCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Installing Required Packages</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mediapipe\n",
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math as m\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Distance between 2 points\n",
    "def findDistance(x1, y1, x2, y2):\n",
    "    dist = m.sqrt((x2-x1)**2+(y2-y1)**2)\n",
    "    return dist\n",
    "\n",
    "# Calculate angle\n",
    "def findAngle(x1, y1, x2, y2):\n",
    "    theta = m.acos((y2 -y1)*(-y1) / (m.sqrt((x2 - x1)**2 + (y2 - y1)**2) * y1))\n",
    "    degree = int(180/m.pi)*theta\n",
    "    return degree\n",
    "\n",
    "# Calculate difference of x-coordinate of two points\n",
    "def findX(x_knee,x_hand):\n",
    "  X = x_hand - x_knee\n",
    "  return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Utils</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Font (For OpenCV Video)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Colors\n",
    "blue = (255, 127, 0)\n",
    "red = (50, 50, 255)\n",
    "green = (127, 255, 0)\n",
    "dark_blue = (127, 20, 0)\n",
    "light_green = (127, 233, 100)\n",
    "yellow = (0, 255, 255)\n",
    "pink = (255, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.8, model_complexity=2, smooth_landmarks=True)\n",
    "\n",
    "# Choose which video to use\n",
    "# ((For webcam input replace file name with 0))\n",
    "# file_name = './videos/coachVids2/IMG_0416.MOV'\n",
    "file_name = './videos/moving2.MOV'\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "\n",
    "# CV2  properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Initialize video writer. might take a look at this again.\n",
    "# video_output = cv2.VideoWriter('test_{0}.mp4'.format(datetime.datetime.now().strftime(\"%d-%m-%Y\")), fourcc, fps, frame_size)\n",
    "video_output = cv2.VideoWriter(\"moving2.mp4\", fourcc, fps, frame_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main Code</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feetInfo = pd.DataFrame(columns=[\"Frame\",\"LH_X\",\"LI_X\", \"Heel Velo\", \"Index Velo\"])\n",
    "feetSizeInfo = pd.DataFrame(columns=['Frame', 'AvgLen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "No frames left to process!!!\n",
      "Video is done!\n"
     ]
    }
   ],
   "source": [
    "print('Starting...')\n",
    "steps = 0\n",
    "stage = None\n",
    "max_dis = 0\n",
    "access = 1\n",
    "velo = 0\n",
    "ball_release = None\n",
    "sliding = False\n",
    "maxFeetLength = 4\n",
    "currentFrame= 0\n",
    "currentframenumber=dict.fromkeys([\"Angle1\",\"Angle2\",\"Angle3\",\"Angle4\",\"Angle5\",\"Release\"])\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "while cap.isOpened():\n",
    "    # Capture frames\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"No frames left to process!!!\")\n",
    "        break\n",
    "    # Get fps, height and width\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    h, w = image.shape[:2]\n",
    "    # Convert the BGR image to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Process the frame with Mediapipe Pose\n",
    "    keypoints = pose.process(image)\n",
    "    # Convert the image back to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    #============ Getting landmarks ============\n",
    "    lm = keypoints.pose_landmarks\n",
    "    lmPose = mp_pose.PoseLandmark\n",
    "    try:\n",
    "        # For Angle Component \n",
    "        l_shldr_x = int(lm.landmark[lmPose.LEFT_SHOULDER].x * w)\n",
    "        l_shldr_y = int(lm.landmark[lmPose.LEFT_SHOULDER].y * h)\n",
    "        r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)\n",
    "        r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)\n",
    "        l_hip_x = int(lm.landmark[lmPose.LEFT_HIP].x * w)\n",
    "        l_hip_y = int(lm.landmark[lmPose.LEFT_HIP].y * h)\n",
    "\n",
    "        # Ankles for feet distance calculation\n",
    "        l_ank_x = int(lm.landmark[lmPose.LEFT_ANKLE].x * 100)\n",
    "        l_ank_y = int(lm.landmark[lmPose.LEFT_ANKLE].y * 100)\n",
    "        r_ank_x = int(lm.landmark[lmPose.RIGHT_ANKLE].x * 100)\n",
    "        r_ank_y = int(lm.landmark[lmPose.RIGHT_ANKLE].y * 100)\n",
    "\n",
    "        r_ind_x = int(lm.landmark[lmPose.RIGHT_INDEX].x * 100)\n",
    "        r_ind_y = int(lm.landmark[lmPose.RIGHT_INDEX].y * 100)\n",
    "        r_heel_x = int(lm.landmark[lmPose.RIGHT_HEEL].x * 100)\n",
    "        r_heel_y = int(lm.landmark[lmPose.RIGHT_HEEL].y * 100)\n",
    "\n",
    "        l_ind_x = int(lm.landmark[lmPose.LEFT_INDEX].x * 100)\n",
    "        l_ind_y = int(lm.landmark[lmPose.LEFT_INDEX].y * 100)\n",
    "        l_heel_x = int(lm.landmark[lmPose.LEFT_HEEL].x * 100)\n",
    "        l_heel_y = int(lm.landmark[lmPose.LEFT_HEEL].y * 100)\n",
    "\n",
    "        if (cap.get(cv2.CAP_PROP_POS_FRAMES) < 20):\n",
    "            feetLength = r_ind_x - r_heel_x\n",
    "            if feetLength > maxFeetLength:\n",
    "                maxFeetLength = feetLength\n",
    "\n",
    "        # For Timing Component\n",
    "        r_wrist_x = int(lm.landmark[lmPose.RIGHT_WRIST].x * w)\n",
    "        r_knee_x = int(lm.landmark[lmPose.RIGHT_KNEE].x * w)\n",
    "        l_knee_x = int(lm.landmark[lmPose.LEFT_KNEE].x * w)\n",
    "\n",
    "        #============ Functions ============\n",
    "\n",
    "        # Check for Camera Alignment to be in Proper Sideview\n",
    "        offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n",
    "        if offset < 100:\n",
    "            cv2.putText(image, str(int(offset)) + ' Aligned', (w - 150, 30), font, 0.9, green, 2)\n",
    "        else:\n",
    "            cv2.putText(image, str(int(offset)) + ' Not Aligned', (w - 150, 30), font, 0.9, red, 2)\n",
    "\n",
    "        # feetDist = findDistance(l_ank_x, l_ank_y, r_ank_x, r_ank_y)\n",
    "        feetDist = abs(findX(l_ank_x, r_ank_x))\n",
    "\n",
    "        # Steps Counter (To be improved - ie Thresholds improvements)\n",
    "        if steps < 5:\n",
    "            if feetDist > maxFeetLength and stage == 'up':\n",
    "                steps += 1\n",
    "                stage = \"down\"\n",
    "            elif feetDist < maxFeetLength:\n",
    "                stage = \"up\"\n",
    "        # Timing Component\n",
    "        # When feet dist is big, then it means it's sliding. Sooooooo enter this\n",
    "        if feetDist > 2*maxFeetLength or sliding==True:\n",
    "            sliding=True\n",
    "            currentFrame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "            pre = currentFrame - 4\n",
    "            if currentFrame > 10:\n",
    "                # Calculate Velocity with this frame and 4 frames before\n",
    "                velo = abs(((l_heel_x - feetInfo[\"LH_X\"][pre])/(currentFrame-pre)))\n",
    "                if velo == 0 and access == 1:\n",
    "                    access = 0\n",
    "                    ball_train_feet_dis = findX(r_knee_x, r_wrist_x)\n",
    "                    ball_slide_feet_dis = findX(l_knee_x, r_wrist_x)\n",
    "                    if ball_train_feet_dis < 0:\n",
    "                        ball_release = \"Late\"\n",
    "                    elif ball_train_feet_dis > 0 and ball_slide_feet_dis < 0:\n",
    "                        ball_release = \"Traditional\"\n",
    "                    elif ball_slide_feet_dis > 0:\n",
    "                        ball_release = \"Early\"\n",
    "                    currentframenumber['Release']=[cap.get(cv2.CAP_PROP_POS_FRAMES)+1]\n",
    "    \n",
    "        # Append to array\n",
    "        feetStuff = {\"Frame\": cap.get(cv2.CAP_PROP_POS_FRAMES)+1, \"LH_X\":l_heel_x,\"LI_X\":l_ind_x,\"Velocity\": velo}\n",
    "        feetInfo = feetInfo.append(feetStuff, ignore_index=True)\n",
    "\n",
    "        # Calculate torso and neck angles\n",
    "        torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n",
    "\n",
    "        #============ Annotations onto video ============\n",
    "        # Draw landmarks\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y - 100), 7, yellow, -1)\n",
    "        # Right shoulder is pink ball\n",
    "        cv2.circle(image, (r_shldr_x, r_shldr_y), 7, pink, -1)\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y - 100), 7, yellow, -1)\n",
    "\n",
    "        # Display the skeleton\n",
    "        # mp_drawing.draw_landmarks(\n",
    "        #     image,\n",
    "        #     keypoints.pose_landmarks,\n",
    "        #     mp_pose.POSE_CONNECTIONS,\n",
    "            \n",
    "        #     landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "        # Text for Neck/Torso Angle, Feet distance & Steps\n",
    "        angle_text_string ='Frame: '+str(cap.get(cv2.CAP_PROP_POS_FRAMES))+' Torso Angle : ' + str(int(torso_inclination)) + 'deg Feet distance: '+ str(int(feetDist)) + ' Steps: '+ str(int(steps)) \n",
    "        # angle_text_string = 'Frame: '+str(cap.get(cv2.CAP_PROP_POS_FRAMES)) +' Feet distance: '+ str(int(feetDist)) + ' Steps: '+ str(int(steps))  + ' Release: '+ str(ball_release) + ' Velocity '+ str(velo)\n",
    "        cv2.putText(image, angle_text_string, (10, 50), font, 1, dark_blue, 4)\n",
    "\n",
    "        # Display angles on the annotation\n",
    "        cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 1.2, pink, 2)\n",
    "\n",
    "        # Join landmarks\n",
    "        cv2.line(image, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), green, 4)\n",
    "        cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), green, 4)\n",
    "        cv2.line(image, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), green, 4)\n",
    "        # if torso_inclination >= 43:\n",
    "        #     detectedFrame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        #     currentframenumber.append(detectedFrame-3)\n",
    "        # # Write frames.\n",
    "        # video_output.write(image)\n",
    "\n",
    "        # Write frames.\n",
    "        video_output.write(image)\n",
    "    except:\n",
    "        print(\"Cannot Detect Anything\")\n",
    "        # Write frames.\n",
    "        video_output.write(image)\n",
    "print('Video is done!')\n",
    "cap.release()\n",
    "video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>LH_X</th>\n",
       "      <th>LI_X</th>\n",
       "      <th>Heel Velo</th>\n",
       "      <th>Index Velo</th>\n",
       "      <th>Velocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>150.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>151.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>152.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>153.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>154.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>155.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>156.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>157.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>158.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>159.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Frame  LH_X  LI_X  Heel Velo  Index Velo  Velocity\n",
       "148  150.0  67.0  75.0        NaN         NaN      0.25\n",
       "149  151.0  67.0  75.0        NaN         NaN      0.25\n",
       "150  152.0  67.0  75.0        NaN         NaN      0.25\n",
       "151  153.0  67.0  75.0        NaN         NaN      0.25\n",
       "152  154.0  67.0  75.0        NaN         NaN      0.25\n",
       "153  155.0  67.0  75.0        NaN         NaN      0.25\n",
       "154  156.0  67.0  72.0        NaN         NaN      0.25\n",
       "155  157.0  67.0  75.0        NaN         NaN      0.25\n",
       "156  158.0  67.0  70.0        NaN         NaN      0.25\n",
       "157  159.0  67.0  65.0        NaN         NaN      0.25"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feetInfo.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Reading Analysed Video for Screenshotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22896/1993552036.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mframeLen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_FRAME_COUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframeLen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mbool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path ='./Analysedphoto'\n",
    "isExist = os.path.exists(path)\n",
    "\n",
    "if not isExist:\n",
    "  # Create a new directory because it does not exist \n",
    "  os.makedirs(path)\n",
    "  print(\"Analysedphoto folder is created!\")\n",
    "\n",
    "cap=cv2.VideoCapture('test_12-07-2022.mp4')\n",
    "ret,frame= cap.read()\n",
    "x=0\n",
    "bool=True\n",
    "testing=[74]\n",
    "frameLen=int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "while bool:\n",
    "    for i in range(0,frameLen,1):\n",
    "        if x>=len(testing):\n",
    "            bool=False\n",
    "            break\n",
    "        # print(\"iv1 \", i)\n",
    "        # print(x<len(currentframenumber))\n",
    "        ret,frame= cap.read()\n",
    "        if i== testing[x]:\n",
    "            print(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            # print(\"iv2\", i)\n",
    "            x=x+1\n",
    "            print(x)\n",
    "            cv2.imwrite(\"Analysedphoto/frame%d.jpg\" % i, frame)     # save frame as JPEG file      \n",
    "            print('Read a new frame: ', ret)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflowgpu2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51181943db1b0af0f2f09fb667233573d956bc74874063b6f328e94a3890e77c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
